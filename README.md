# SignLanguageTranslation

Głównym celem projektu jest zbudowanie bazy dla aktywnego translatora języka migowego. Aplikacja zbudowana zostanie przy pomocy Azure Custom Vision i pozwoli na rozpoznawanie różnych gestów z alfabetu oraz z umownego języka migowego.

<img src='/Images/Alfabet.jpg' width=400>

## Rozpoznawane gesty

Warto zaznaczyć, że porozumiewanie się w sposób alfabetyczny jest wysoce nieefektywne, z tego powodu powstał język umowny, który funkcjonuje wśród głuchniemych. Jezyk taki pozwala na znacznie szybsze przekazywanie informacji niż język alfabetyczny. 

Aplikacja ma być jedynie demem możliwości które w później można dalej rozwijać przez douczanie słownika nowych gestów. Na początku translator będzie rozpoznawał jedynie gesty 'I', 'L', 'Y' oraz złożony gest 'Kocham cię'. Pochodzenie złożonego gestu przedstawione jest na ilustracji poniżej.

<img src='/Images/ILY.jpg' width=400>

## Baza danych uczących

Cała baza danych uczacych znajduje się w folderze ./src/images.



